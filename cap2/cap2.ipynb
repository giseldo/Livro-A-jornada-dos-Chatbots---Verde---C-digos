{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457486dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você: Eu estou feliz\n",
      "Eliza: Você disse: Eu estou feliz\n",
      "Você: Eu estou alegre\n",
      "Eliza: Você disse: Eu estou alegre\n"
     ]
    }
   ],
   "source": [
    "# método que processa a entrada do usuário\n",
    "def response(user_input):\n",
    "\treturn \"Você disse: \" + user_input\n",
    "\n",
    "# Exemplo de uso\n",
    "user_input = \"Eu estou feliz\"\n",
    "print(\"Você: {}\".format(user_input))\n",
    "print(\"Eliza: {}\".format(response(user_input)))\n",
    "user_input = \"Eu estou alegre\"\n",
    "print(\"Você: {}\".format(user_input))\n",
    "print(\"Eliza: {}\".format(response(user_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62dbb236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello.\n",
      "Bot: Hello. How do you do. Please tell me your problem.\n",
      "User: I am feeling sad.\n",
      "Bot: Why do you think you are feeling sad.?\n",
      "Maybe I was not good enough.\n",
      "Bot: You don't seem certain.\n",
      "My mother tried to help.\n",
      "Bot: Tell me more about your family.\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "import random  \n",
    "\n",
    "regras = [\n",
    "    (re.compile(r'\\b(hello|hi|hey)\\b', re.IGNORECASE),\n",
    "     [\"Hello. How do you do. Please tell me your problem.\"]), # regra 1\n",
    "    (re.compile(r'\\b(I am|I\\'?m) (.+)', re.IGNORECASE), # regra 2\n",
    "     [\"How long have you been {1}?\",   \n",
    "      \"Why do you think you are {1}?\"]),\n",
    "    (re.compile(r'\\bI need (.+)', re.IGNORECASE), # regra 3\n",
    "     [\"Why do you need {1}?\",\n",
    "      \"Would it really help you to get {1}?\"]),\n",
    "    (re.compile(r'\\bI can\\'?t (.+)', re.IGNORECASE), # regra 4\n",
    "     [\"What makes you think you can't {1}?\",\n",
    "      \"Have you tried {1}?\"]),\n",
    "    (re.compile(r'\\bmy (mother|father|mom|dad)\\b', re.IGNORECASE), # regra 5\n",
    "     [\"Tell me more about your family.\",\n",
    "      \"How do you feel about your parents?\"]),\n",
    "    (re.compile(r'\\b(sorry)\\b', re.IGNORECASE), # regra 6\n",
    "     [\"Please don't apologize.\"]),\n",
    "    (re.compile(r'\\b(maybe|perhaps)\\b', re.IGNORECASE), # regra 7\n",
    "     [\"You don't seem certain.\"]),\n",
    "    (re.compile(r'\\bbecause\\b', re.IGNORECASE), # regra 8\n",
    "     [\"Is that the real reason?\"]),\n",
    "    (re.compile(r'\\b(are you|do you) (.+)\\?$', re.IGNORECASE), # regra 9\n",
    "     [\"Why do you ask that?\"]),\n",
    "    (re.compile(r'\\bcomputer\\b', re.IGNORECASE), # regra 10\n",
    "     [\"Do computers worry you?\"]),\n",
    "]\n",
    "\n",
    "respostas_padrao = [\n",
    "    \"I see.\",  \n",
    "    \"Please tell me more.\",  \n",
    "    \"Can you elaborate on that?\"  \n",
    "]\n",
    "\n",
    "def response(entrada_usuario):\n",
    "    for padrao, respostas in regras:\n",
    "        match = padrao.search( entrada_usuario)  \n",
    "        if match:\n",
    "            resposta = random.choice(respostas)\n",
    "            if match.groups():\n",
    "                resposta = resposta.format( *match.groups())\n",
    "            return resposta\n",
    "    return random.choice(respostas_padrao)\n",
    "\n",
    "print(\"User: Hello.\")\n",
    "print(\"Bot: \" + response(\"Hello.\"))\n",
    "print(\"User: I am feeling sad.\")\n",
    "print(\"Bot: \" + response(\"I am feeling sad.\"))\n",
    "print(\"Maybe I was not good enough.\")\n",
    "print(\"Bot: \" + response(\"Maybe I was not good enough.\"))\n",
    "print(\"My mother tried to help.\")\n",
    "print(\"Bot: \" + response(\"My mother tried to help.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1886cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatbot(message, history):\n",
    "    resposta = \"Olá! Eu sou um chatbot. Como posso ajudar você?\"\n",
    "    return resposta\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot,\n",
    "    title=\"Chatbot Simples\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1574010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install gradio\n",
    "import gradio as gr\n",
    "\n",
    "def chatbot(message, history):\n",
    "    if \"Olá\" in message:\n",
    "        resposta = \"Olá! Eu sou um chatbot. Como posso ajudar você?\"\n",
    "    elif \"Quem é você?\" in message:\n",
    "        resposta = \"Eu sou um chatbot criado para ajudar você com suas perguntas.\"\n",
    "    else:\n",
    "        resposta = \"Desculpe, não entendi sua pergunta. Pode tentar novamente?\"\n",
    "    return resposta\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot,\n",
    "    title=\"Chatbot Simples\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4bb7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install gradio\n",
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "def chatbot(message, history):\n",
    "    respostas = [\"Interessante!\", \"Hmm, me conte mais!\", \"Não sei, mas vou fingir que sim!\"]\n",
    "    if \"Olá\" in message:\n",
    "        resposta = \"Olá! Eu sou um chatbot. Como posso ajudar você?\"\n",
    "    elif \"Quem é você?\" in message:\n",
    "        resposta = \"Eu sou um chatbot criado para ajudar você com suas perguntas.\"\n",
    "    else:\n",
    "        resposta = random.choice(respostas)        \n",
    "    return resposta\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot,\n",
    "    title=\"Chatbot Simples\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8a346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiml\n",
      "  Obtaining dependency information for aiml from https://files.pythonhosted.org/packages/06/e7/b65203e655249c0f679f41fdec824eb57c964253bac4c87bf00015845b7f/aiml-0.9.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached aiml-0.9.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from aiml) (80.9.0)\n",
      "Using cached aiml-0.9.2-py2.py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: aiml\n",
      "Successfully installed aiml-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install aiml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158de0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cerebro.aiml..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\aiml\\Kernel.py:1015: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  elem[2] = re.sub(\"\\s+\", \" \", elem[2])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'clock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(cerebro_aiml_text)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Carregar o arquivo AIML\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcerebro.aiml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Loop de conversa\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\aiml\\Kernel.py:335\u001b[0m, in \u001b[0;36mKernel.learn\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(filename):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verboseMode: \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m f, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 335\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m()\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# Load and parse the AIML file.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     parser \u001b[38;5;241m=\u001b[39m create_parser()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'time' has no attribute 'clock'"
     ]
    }
   ],
   "source": [
    "# pip install aiml\n",
    "import aiml\n",
    "# Criar kernel (núcleo do bot)\n",
    "kernel = aiml.Kernel()\n",
    "cerebro_aiml_text = \"\"\"\n",
    "<aiml version=\"1.0.1\" encoding=\"UTF-8\">\n",
    "\t<category>\n",
    "\t\t<pattern>OI</pattern>\n",
    "\t\t<template>Olá! Como posso ajudar você?</template>\n",
    "\t</category>\n",
    "\t<category>\n",
    "\t\t<pattern>OBRIGADO</pattern>\n",
    "\t\t<template>De nada!</template>\n",
    "\t</category>\n",
    "</aiml>\n",
    "\"\"\"\n",
    "\n",
    "# Salvar o conteúdo AIML em um arquivo\n",
    "with open(\"cerebro.aiml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cerebro_aiml_text)\n",
    "# Carregar o arquivo AIML\n",
    "kernel.learn(\"cerebro.aiml\")\n",
    "\n",
    "# Loop de conversa\n",
    "while True:\n",
    "\tuser_input = input(\"Você: \")\n",
    "\tif user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "\t\tbreak\n",
    "\tresponse = kernel.respond(user_input)\n",
    "\tprint(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36802d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
